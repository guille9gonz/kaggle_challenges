{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building for Spaceship Titanic challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data analysis and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravior Noxnuther</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1499/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurta Mondalley</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fayey Connon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>Celeon Hontichre</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Propsh Hontichre</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n",
       "1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n",
       "2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n",
       "3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n",
       "4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n",
       "...          ...        ...       ...       ...            ...   ...    ...   \n",
       "8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n",
       "8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n",
       "8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
       "8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n",
       "8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "...           ...        ...           ...     ...     ...                ...   \n",
       "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n",
       "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n",
       "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n",
       "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n",
       "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n",
       "\n",
       "      Transported  \n",
       "0           False  \n",
       "1            True  \n",
       "2           False  \n",
       "3           False  \n",
       "4            True  \n",
       "...           ...  \n",
       "8688        False  \n",
       "8689        False  \n",
       "8690         True  \n",
       "8691        False  \n",
       "8692         True  \n",
       "\n",
       "[8693 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(r'datasets/train.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(f'Number of duplicated rows: {df_train.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "PassengerId       0\n",
      "HomePlanet      201\n",
      "CryoSleep       217\n",
      "Cabin           199\n",
      "Destination     182\n",
      "Age             179\n",
      "VIP             203\n",
      "RoomService     181\n",
      "FoodCourt       183\n",
      "ShoppingMall    208\n",
      "Spa             183\n",
      "VRDeck          188\n",
      "Name            200\n",
      "Transported       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for Nan values\n",
    "print('Missing values:')\n",
    "print(df_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Transported to numerical values\n",
    "df_train['Transported'] = df_train['Transported'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1. Handle numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows with some num column missing: 908\n",
      "Average billed amount (if billed): 2546.85€\n",
      "Average billed amount (total): 1484.60€\n"
     ]
    }
   ],
   "source": [
    "# Calculate a new column for the total amount spent within all services\n",
    "df_train['Billed'] = df_train['RoomService'] + df_train['FoodCourt'] + df_train['ShoppingMall'] + df_train['Spa'] + df_train['VRDeck']\n",
    "print('Total rows with some num column missing:', df_train['Billed'].isna().sum())\n",
    "print(f'Average billed amount (if billed): {df_train[df_train['Billed'] != 0]['Billed'].mean():.2f}€')\n",
    "print(f'Average billed amount (total): {df_train['Billed'].mean():.2f}€')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN based on the bill\n",
    "billed_min = 1484.60\n",
    "billed_max = 2546.85\n",
    "nan_bill = df_train['Billed'].isna()\n",
    "\n",
    "# Applies max amount if condition is satisfied (> 0) and min amount if not (0)\n",
    "replace_bill = np.where(df_train[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].gt(0).any(axis=1),\n",
    "                        billed_min,\n",
    "                        billed_max)\n",
    "df_train.loc[nan_bill, 'Billed'] = replace_bill[nan_bill]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN of numerical cols\n",
    "def fillna_num_cols(row):\n",
    "    target = row['Billed']\n",
    "    num_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    num_sum = row[num_cols].sum(skipna=True) # Sum of non NaN values\n",
    "    row[num_cols] = row[num_cols].fillna((target - num_sum)/row[num_cols].isna().sum())\n",
    "    return row\n",
    "\n",
    "df_train = df_train.apply(fillna_num_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Age with the mean\n",
    "mean_age = df_train['Age'].mean()\n",
    "df_train['Age'].fillna(mean_age, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2. HomePlanet and Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Route\n",
       "Earth_TRAPPIST-1e        3101\n",
       "Mars_TRAPPIST-1e         1475\n",
       "Europa_TRAPPIST-1e       1189\n",
       "Europa_55 Cancri e        886\n",
       "Earth_PSO J318.5-22       712\n",
       "Earth_55 Cancri e         690\n",
       "Mars_55 Cancri e          193\n",
       "Unknown_TRAPPIST-1e       150\n",
       "Earth_Unknown              99\n",
       "Mars_PSO J318.5-22         49\n",
       "Mars_Unknown               42\n",
       "Europa_Unknown             37\n",
       "Unknown_55 Cancri e        31\n",
       "Europa_PSO J318.5-22       19\n",
       "Unknown_PSO J318.5-22      16\n",
       "Unknown_Unknown             4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new column with the route (home - destination)\n",
    "df_train['Route'] = df_train['HomePlanet'].fillna('Unknown') + \"_\" + df_train['Destination'].fillna('Unknown')\n",
    "\n",
    "# Fill with the most common home/destination for each route\n",
    "df_train['Route'].value_counts()\n",
    "\n",
    "# Unknown_Trappist --> Earth_Trappist\n",
    "# Earth_Unknown --> Earth_Trappist\n",
    "# Mars_Unknown --> Mars_Trappist\n",
    "# Europa_Unknown --> Europa_Trappist\n",
    "# Unknown_Cancri --> Europa_Cancri\n",
    "# Unknown_PSO --> Mars_PSO\n",
    "# Unknown_Unknown --> Earth_Trappist (most common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_routes(df):\n",
    "    routes = ['Unknown_TRAPPIST-1e', 'Earth_Unknown', 'Mars_Unknown', 'Europa_Unknown', 'Unknown_55 Cancri e', 'Unknown_PSO J318.5-22', 'Unknown_Unknown']\n",
    "    for route in routes:\n",
    "        if route in ['Unknown_TRAPPIST-1e', 'Earth_Unknown', 'Unknown_Unknown']:\n",
    "            df.loc[df['Route'] == route, 'Route'] = 'Earth_TRAPPIST-1e'\n",
    "        elif route == 'Mars_Unknown':\n",
    "            df.loc[df['Route'] == route, 'Route'] = 'Mars_TRAPPIST-1e'\n",
    "        elif route == 'Europa_Unknown':\n",
    "            df.loc[df['Route'] == route, 'Route'] = 'Europa_TRAPPIST-1e'\n",
    "        elif route == 'Unknown_55 Cancri e':\n",
    "            df.loc[df['Route'] == route, 'Route'] = 'Europa_55 Cancri e'\n",
    "        elif route == 'Unknown_PSO J318.5-22':\n",
    "            df.loc[df['Route'] == route, 'Route'] = 'Mars_PSO J318.5-22'\n",
    "    return df\n",
    "\n",
    "df_train = set_routes(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Route using Leave-One-Out Encoding\n",
    "leave_route = ce.LeaveOneOutEncoder(cols=['Route'])\n",
    "df_train['Route'] = leave_route.fit_transform(df_train['Route'], df_train['Transported'])\n",
    "\n",
    "# Drop Home and Destination columns\n",
    "df_train.drop(columns=['HomePlanet', 'Destination'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3. VIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill VIP with the most common (False, by a huge difference)\n",
    "mode_vip = df_train['VIP'].mode()[0]\n",
    "df_train['VIP'].fillna(mode_vip, inplace=True)\n",
    "\n",
    "# Convert to int\n",
    "df_train['VIP'] = df_train['VIP'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4. CryoSleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with the most common Cryo for each route\n",
    "df_mode_cryo = df_train.groupby('Route')['CryoSleep'].agg(lambda x: x.mode()[0])\n",
    "\n",
    "# Fill NaN in Cryo with the most common bool based on the route\n",
    "df_train['CryoSleep'] = df_train.apply(\n",
    "    lambda row: df_mode_cryo[row['Route']] if pd.isna(row['CryoSleep'])\n",
    "    else row['CryoSleep'],\n",
    "    axis=1)\n",
    "\n",
    "# Convert to int\n",
    "df_train['CryoSleep'] = df_train['CryoSleep'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5. Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN with Unknown\n",
    "df_train['Name'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Create separated column for surnames only\n",
    "df_train['Surname'] = df_train['Name'].apply(lambda x: str(x).split()[-1])\n",
    "\n",
    "# Drop Name column\n",
    "df_train.drop(columns=['Name'], inplace=True)\n",
    "\n",
    "# Encode Surname\n",
    "leave_surname = ce.LeaveOneOutEncoder(cols=['Surname'])\n",
    "df_train['Surname'] = leave_surname.fit_transform(df_train['Surname'], df_train['Transported'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6. Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN based on Surname\n",
    "df_surname_cabin = df_train.dropna(subset=['Cabin']).groupby('Surname')['Cabin'].first()\n",
    "df_train['Cabin'] = df_train['Cabin'].fillna(df_train['Surname'].map(df_surname_cabin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Cabin into Deck, Number and Side\n",
    "df_train[['Cabin_deck', 'Cabin_num', 'Cabin_side']] = df_train['Cabin'].str.split('/', expand=True)\n",
    "\n",
    "# Drop Cabin column now\n",
    "df_train.drop(columns=['Cabin'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Deck\n",
    "leave_deck = ce.LeaveOneOutEncoder(cols=['Cabin_deck'])\n",
    "df_train['Cabin_deck'] = leave_deck.fit_transform(df_train['Cabin_deck'], df_train['Transported'])\n",
    "\n",
    "# Convert Num into int\n",
    "df_train['Cabin_num'] = df_train['Cabin_num'].astype(int)\n",
    "\n",
    "# Binary encode Side\n",
    "df_train['Cabin_side'] = df_train['Cabin_side'].map({'P': 1, 'S': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6. Check dataset and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Billed</th>\n",
       "      <th>Route</th>\n",
       "      <th>Surname</th>\n",
       "      <th>Cabin_deck</th>\n",
       "      <th>Cabin_num</th>\n",
       "      <th>Cabin_side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.635918</td>\n",
       "      <td>0.503624</td>\n",
       "      <td>0.731893</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0.393379</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.441805</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>0.635918</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>0.635918</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>0.393379</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.441805</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  CryoSleep   Age  VIP  RoomService  FoodCourt  ShoppingMall  \\\n",
       "0     0001_01          0  39.0    0          0.0        0.0           0.0   \n",
       "1     0002_01          0  24.0    0        109.0        9.0          25.0   \n",
       "2     0003_01          0  58.0    1         43.0     3576.0           0.0   \n",
       "3     0003_02          0  33.0    0          0.0     1283.0         371.0   \n",
       "4     0004_01          0  16.0    0        303.0       70.0         151.0   \n",
       "\n",
       "      Spa  VRDeck  Transported   Billed     Route   Surname  Cabin_deck  \\\n",
       "0     0.0     0.0            0      0.0  0.635918  0.503624    0.731893   \n",
       "1   549.0    44.0            1    736.0  0.393379  1.000000    0.441805   \n",
       "2  6715.0    49.0            0  10383.0  0.635918  0.600000    0.500000   \n",
       "3  3329.0   193.0            0   5176.0  0.635918  0.600000    0.500000   \n",
       "4   565.0     2.0            1   1091.0  0.393379  0.400000    0.441805   \n",
       "\n",
       "   Cabin_num  Cabin_side  \n",
       "0          0           1  \n",
       "1          0           0  \n",
       "2          0           0  \n",
       "3          0           0  \n",
       "4          1           0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId     0\n",
       "CryoSleep       0\n",
       "Age             0\n",
       "VIP             0\n",
       "RoomService     0\n",
       "FoodCourt       0\n",
       "ShoppingMall    0\n",
       "Spa             0\n",
       "VRDeck          0\n",
       "Transported     0\n",
       "Billed          0\n",
       "Route           0\n",
       "Surname         0\n",
       "Cabin_deck      0\n",
       "Cabin_num       0\n",
       "Cabin_side      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Prepare training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['CryoSleep', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Billed', 'Route', 'Surname', 'Cabin_deck', 'Cabin_num', 'Cabin_side']\n",
    "X = df_train[features]\n",
    "y = df_train.Transported\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training and validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joblib already saved\n"
     ]
    }
   ],
   "source": [
    "# Save encoders and scaler for testing\n",
    "if not os.path.exists('joblib_files'):\n",
    "    os.makedirs('joblib_files')\n",
    "    joblib.dump(leave_route, 'leave_route.joblib')\n",
    "    joblib.dump(leave_surname, 'leave_surname.joblib')\n",
    "    joblib.dump(leave_deck, 'leave_deck.joblib')\n",
    "    joblib.dump(scaler, 'scaler.joblib')\n",
    "else:\n",
    "    print('Joblib already saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Select Machine Learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. Histogram-Based Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gbc = HistGradientBoostingClassifier(max_iter=100, random_state=10)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "y_gbc_pred = gbc.predict(X_valid)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_valid, y_gbc_pred)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.56%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etc = ExtraTreesClassifier(n_estimators=100, max_depth=None, min_samples_split=5, random_state=11)\n",
    "etc.fit(X_train, y_train)\n",
    "\n",
    "y_etc_pred = etc.predict(X_valid)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_valid, y_etc_pred)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3. Bagging meta-estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.54%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "bme = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5, random_state=12)\n",
    "bme.fit(X_train, y_train)\n",
    "\n",
    "y_bme_pred = bme.predict(X_valid)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_valid, y_bme_pred)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4. Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (soft voting): 89.88%\n",
      "Accuracy (hard voting): 77.97%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "cl_rf = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "cl_nb = GaussianNB()\n",
    "cl_lr = LogisticRegression(random_state=1)\n",
    "cl_svc = SVC(kernel='linear', probability=True)\n",
    "\n",
    "vc_soft = VotingClassifier(\n",
    "    estimators=[('rf', cl_rf), ('nb', cl_nb), ('lr', cl_lr), ('svc', cl_svc)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "vc_hard = VotingClassifier(\n",
    "    estimators=[('rf', cl_rf), ('nb', cl_nb), ('lr', cl_lr), ('svc', cl_svc)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "vc_soft.fit(X_train, y_train)\n",
    "vc_hard.fit(X_train, y_train)\n",
    "\n",
    "y_soft_pred = vc_soft.predict(X_valid)\n",
    "y_hard_pred = vc_hard.predict(X_valid)\n",
    "\n",
    "print(f'Accuracy (soft voting): {accuracy_score(y_valid, y_soft_pred)*100:.2f}%')\n",
    "print(f'Accuracy (hard voting): {accuracy_score(y_valid, y_hard_pred)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest: 98.90%\n",
      "Accuracy of Naive-Bayes: 67.25%\n",
      "Accuracy of Logistic Regression: 76.08%\n",
      "Accuracy of SVC: 89.88%\n"
     ]
    }
   ],
   "source": [
    "for clf, label in zip([cl_rf, cl_nb, cl_lr, vc_soft], ['Random Forest', 'Naive-Bayes', 'Logistic Regression', 'SVC', 'Ensemble']):\n",
    "    clf.fit(X_train, y_train)\n",
    "    prediction = clf.predict(X_valid)\n",
    "    score = accuracy_score(y_valid, prediction)\n",
    "    print(f'Accuracy of {label}: {score*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5. AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.49%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "abc = AdaBoostClassifier(n_estimators=100, algorithm='SAMME', random_state=14)\n",
    "abc.fit(X_train, y_train)\n",
    "\n",
    "y_abc_pred = abc.predict(X_valid)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_valid, y_abc_pred)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already saved\n"
     ]
    }
   ],
   "source": [
    "# Save the best model: HB Gradient Boosting\n",
    "if not os.path.exists('joblib_files/gbc_model.joblib'):\n",
    "    joblib.dump(gbc, 'joblib_files/gbc_model.joblib')\n",
    "else:\n",
    "    print('Model already saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
